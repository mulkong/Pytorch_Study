{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Size and Resize\n",
    "\n",
    "### 1-1. Get the size and type of 'x'\n",
    "\n",
    "- torch.tensor는 numpy 와 비슷하게 사용이 가능하지만, shape을 확인할땐 ***size()***로 확인을 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch tensor size : torch.Size([3, 2, 1])\n",
      "torch tensor type : torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 1) # (3, 2, 1) shape을 갖고 랜덤값으로 채워준다.\n",
    "y = x.size() # torch.tensor인 x의 size를 확인한다\n",
    "\n",
    "print(\"torch tensor size : {}\".format(y))\n",
    "print(\"torch tensor type : {}\".format(x.type()))\n",
    "\n",
    "assert y==x.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Get the total number of elements in x\n",
    "- .numel() : torch.tensor 값들의 총 합을 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor([[[ 0.0729,  0.0468],\n",
      "         [ 0.7216, -0.3420]],\n",
      "\n",
      "        [[-1.4557, -1.4376],\n",
      "         [ 0.3464,  1.7269]],\n",
      "\n",
      "        [[ 1.2108, -0.4587],\n",
      "         [-1.5447, -1.2787]]])\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 2) #기본적으노 Float tensor로 setting이 된다.\n",
    "print(x.type())\n",
    "y = x.numel() # (3, 2, 2) 차원을 갖는 x의 원소 합을 구하는 함수\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Get the number of dimensions of x\n",
    "\n",
    "- Tensorflow and Keras shape : (H, W, C)\n",
    "- Pytorch shape : (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 차원 :  3\n",
      "torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 1)\n",
    "print(\"x의 차원 : \", x.dim())\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. Resize x to shape of (10, 3)\n",
    "\n",
    "torch로 shape을 변경해가며 model에 넣어줄때, shape을 변경해야할 경우가 생기게 된다. 이때, 전체 함이 값은 값이 나온다는 전재하네 shape을 변경할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n",
      "tensor([[ 0.8541, -0.3166,  0.6494, -0.3390, -1.4015,  0.7518],\n",
      "        [-0.5903,  0.0742,  0.8404,  0.3509,  0.2091,  0.7638],\n",
      "        [ 1.4224, -0.7578, -0.6472, -1.1049,  0.8404,  0.8299],\n",
      "        [ 1.6354, -0.8514, -0.3302,  0.1855, -0.7958, -1.4168],\n",
      "        [ 0.3381,  0.4326, -0.2390, -0.7901,  0.3790,  0.6520]])\n",
      "\n",
      "=====Resize=====\n",
      "\n",
      "torch.Size([10, 3])\n",
      "tensor([[ 0.8541, -0.3166,  0.6494],\n",
      "        [-0.3390, -1.4015,  0.7518],\n",
      "        [-0.5903,  0.0742,  0.8404],\n",
      "        [ 0.3509,  0.2091,  0.7638],\n",
      "        [ 1.4224, -0.7578, -0.6472],\n",
      "        [-1.1049,  0.8404,  0.8299],\n",
      "        [ 1.6354, -0.8514, -0.3302],\n",
      "        [ 0.1855, -0.7958, -1.4168],\n",
      "        [ 0.3381,  0.4326, -0.2390],\n",
      "        [-0.7901,  0.3790,  0.6520]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kojaeyeong/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/tensor.py:314: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 6)\n",
    "print(x.size())\n",
    "print(x)\n",
    "\n",
    "print(\"\\n=====Resize=====\\n\")\n",
    "\n",
    "x_resize = x.resize(10, 3)\n",
    "print(x_resize.size())\n",
    "print(x_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-5. Remove all the dimensions of size 1 in x\n",
    "\n",
    "- squeeze() : 1값을 갖는 차원을 제거해주는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 1, 1])\n",
      "torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 6, 1, 1)\n",
    "print(x.size())\n",
    "\n",
    "y = x.squeeze()\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-6. Remove only the thrid dimenstion in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 6, 1, 3)\n",
    "y = x.squeeze(2)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-7. Remove only the last dimenstion in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 1, 3, 1])\n",
      "torch.Size([10, 6, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 6, 1, 3, 1)\n",
    "print(x.size())\n",
    "y = x.squeeze(-1)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-8.Add a dimenstion of 1 at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 3])\n",
      "torch.Size([10, 10, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x  = torch.ones(10, 10, 3)\n",
    "print(x.size())\n",
    "y = x.unsqueeze(-1)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-9. Convert 1 dim to 3 dim (using the ***np.concatenate***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 1)\n",
      "(10, 10, 3)\n",
      "torch.Size([10, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 10, 1)\n",
    "x_numpy = x.numpy()\n",
    "print(x_numpy.shape)\n",
    "\n",
    "x_concat = np.concatenate((x_numpy, np.concatenate((x_numpy, x_numpy), axis=-1)), axis=-1)\n",
    "print(x_concat.shape)\n",
    "x_tensor = torch.from_numpy(x_concat)\n",
    "print(x_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Indexing, Slicing, Joining, Mutating ops\n",
    "\n",
    "### 2-1. Resize를 해주고 indexing 해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21])\n",
      "\n",
      "====== Resize ======\n",
      "\n",
      "torch.Size([3, 7])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19, 20, 21]])\n",
      "\n",
      "====== indexing ======\n",
      "\n",
      "tensor([0, 2, 4, 5])\n",
      "\n",
      "[indexing] \n",
      "tensor([[ 1,  3,  5,  6],\n",
      "        [ 8, 10, 12, 13],\n",
      "        [15, 17, 19, 20]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 22)\n",
    "print(x.size())\n",
    "print(x)\n",
    "\n",
    "print(\"\\n====== Resize ======\\n\")\n",
    "\n",
    "x_resize = x.resize(3, 7)\n",
    "print(x_resize.size())\n",
    "print(x_resize)\n",
    "\n",
    "print(\"\\n====== indexing ======\\n\")\n",
    "y = torch.LongTensor([0, 2, 4, 5])\n",
    "print(y)\n",
    "print(\"\\n[indexing] \\n{}\".format(x_resize.index_select(1, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Mask 씌워주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([False, False, False, False,  True,  True,  True,  True,  True,  True])\n",
      "tensor([ 5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 11)\n",
    "print(x)\n",
    "mask = x.gt(4) # 4번째 index 부터는 True로(1) 그 이하는 False(0)으로 채우기\n",
    "print(mask)\n",
    "print(x.masked_select(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 2차원 크기를 동일한 크기로 tensor를 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "\n",
      "===== split tensor =====\n",
      "\n",
      "(tensor([[1, 2, 3, 4, 5]]), tensor([[ 6,  7,  8,  9, 10]]))\n",
      "<class 'tuple'>\n",
      "tensor1 : tensor([[1, 2, 3, 4, 5]]), tensor2 : tensor([[ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 11).resize(2, 5)\n",
    "print(x.size())\n",
    "print(x)\n",
    "\n",
    "print(\"\\n===== split tensor =====\\n\")\n",
    "\n",
    "y_chunk = x.chunk(5)\n",
    "print(y_chunk)\n",
    "print(type(y_chunk))\n",
    "\n",
    "tensor1, tensor2 = y_chunk\n",
    "print(\"tensor1 : {}, tensor2 : {}\".format(tensor1, tensor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n",
      "<class 'tuple'>\n",
      "(tensor([1, 6]), tensor([2, 7]), tensor([3, 8]), tensor([4, 9]), tensor([ 5, 10]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 11).resize(2, 5)\n",
    "print(x)\n",
    "\n",
    "y_split = torch.unbind(x, axis=1)\n",
    "print(type(y_split))\n",
    "print(y_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Stack x, y and z vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]], dtype=torch.int32)\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.IntTensor([1, 4])\n",
    "y = torch.IntTensor([2, 5])\n",
    "z = torch.IntTensor([3, 6])\n",
    "\n",
    "tensor_stack = torch.stack((x, y,z), dim=0)\n",
    "print(tensor_stack)\n",
    "print(tensor_stack.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. Concatenate X and Y along the first dimenstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = torch.FloatTensor([[7, 8, 9], [10, 11, 12]])\n",
    "z = torch.cat((x, y), dim=0)\n",
    "#z = torch.stack((x, y), dim=0) # --> (2, 2, 3) 이 되버림.\n",
    "print(z)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. Transpose First and second dimenstion of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3929,  1.6695],\n",
      "        [ 0.1826,  0.9148],\n",
      "        [-0.5228, -0.4459]])\n",
      "torch.Size([3, 2])\n",
      "\n",
      "=====Transpos=====\n",
      "\n",
      "tensor([[-0.3929,  0.1826, -0.5228],\n",
      "        [ 1.6695,  0.9148, -0.4459]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 2)\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(\"\\n=====Transpos=====\\n\")\n",
    "y = x.t()\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-7. *Dimenstion 순서 변경하기*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, 2, 3)\n",
    "print(x.size())\n",
    "y = x.permute(2, 0, 1)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [3., 1.]])\n",
      "torch.Size([2, 2])\n",
      "sorted tensor :  tensor([[1., 4.],\n",
      "        [1., 3.]])\n",
      "sorted indices :  tensor([[0, 1],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 4], [3, 1]])\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "sorted_tensor, sorted_indices = x.sort(1)\n",
    "print(\"sorted tensor : \", sorted_tensor)\n",
    "print(\"sorted indices : \", sorted_indices)\n",
    "#3과 1이 위치가 바뀌면서 정렬(sort)된걸 볼 수 있따, 그래서 index에서 위치가 변경됬다고 알려주는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Counting\n",
    "\n",
    "### 4-1. zero가 아닌 값들의 위치를 알려줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  7.,  0.,  0.],\n",
      "        [ 3.,  0.,  0.,  2., 19.]])\n",
      "torch.Size([2, 5])\n",
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 3],\n",
      "        [1, 4]])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[0,1,7,0,0], [3,0,0,2,19]])\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "y = x.nonzero()\n",
    "print(y) # 2차원 이다. 0행 1열, 0행 2열, 1행 0열 이 0이 아닌 값이라는걸 알려주는 것.\n",
    "print(y.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
